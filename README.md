# intro_to_LMMs

## Introduction

This repository has some teaching resources for a course on introduction to large language models (LMMs). 


## Resources

* very good visual explanation of LLMs and transformers

  https://ig.ft.com/generative-ai/

* Introduction to LLMs theory

  https://docs.science.ai.cam.ac.uk/large-language-models/Introduction/Introduction/

* Andrej Karpathy build GPT-2 ground up

https://www.youtube.com/watch?v=kCc8FmEb1nY

* Vizuara videos

  https://www.youtube.com/watch?v=Xpr8D6LeAtw&list=PLPTV0NXA_ZSgsLAr8YCgCwhPIJNNtexWu

  https://www.vizuaranewsletter.com/p/9e1

* 3blue1brown videos

VERY GOOD playlist on deep learning, LLMs and transformers

https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi

Embedding video

Attention video

https://www.youtube.com/watch?v=wjZofJX0v4M

  Transformer video

https://www.youtube.com/watch?v=eMlx5fFNoYc&vl=en

https://www.3blue1brown.com/lessons/gpt


* Attention	

Introduction to attention mechanism (VERY GOOD)

https://www.youtube.com/watch?v=XN7sevVxyUM

Animation

https://jalammar.github.io/illustrated-transformer/

https://en.wikipedia.org/wiki/Attention_(machine_learning)#/media/File:Attention-qkv.png

https://en.wikipedia.org/wiki/Attention_(machine_learning)

* Next token prediction

  https://medium.com/@akash.kesrwani99/understanding-next-token-prediction-concept-to-code-1st-part-7054dabda347

* LangChain and huggingface open source model example

  https://python.langchain.com/docs/integrations/chat/huggingface/

## Code

https://github.com/acceleratescience/large-language-models

https://github.com/acceleratescience/hands-on-llms

https://docs.science.ai.cam.ac.uk/hands-on-llms/setting-up/codespaces/

`L2_NLP_transformers.ipynb`: Simple code to call a facebook open-source model

https://github.com/neelsoumya/intro_to_LMMs/blob/main/L2_NLP_transformers.ipynb

Transformers from scratch

`[1_1]_Transformer_from_Scratch_(exercises).ipynb`

https://github.com/neelsoumya/intro_to_LMMs/blob/main/%5B1_1%5D_Transformer_from_Scratch_(exercises).ipynb

`text_classification_with_transformer.ipynb`: Multi-head attention transformers in Keras

https://github.com/neelsoumya/intro_to_LMMs/blob/main/text_classification_with_transformer.ipynb

`tiktoken_demo.ipynb`: Code to explain tokenizer

https://github.com/neelsoumya/intro_to_LMMs/blob/main/tiktoken_demo.ipynb


## Project and hackathon

https://github.com/neelsoumya/CFD_LLM_Accelerate24

https://github.com/neelsoumya/LLM-Handon


## User interfaces

* Streamlit

* https://docs.science.ai.cam.ac.uk/large-language-models/streamlit/



## Acknowledgement

Accelerate Science and Ryan Daniels

https://science.ai.cam.ac.uk/

https://docs.science.ai.cam.ac.uk/training/#accelerate-workshops

https://github.com/acceleratescience/diffusion-models

https://docs.science.ai.cam.ac.uk/large-language-models/

https://docs.science.ai.cam.ac.uk/diffusion-models/Introduction/Introduction/

https://science.ai.cam.ac.uk/team/ryan-daniels

https://docs.science.ai.cam.ac.uk/large-language-models/Introduction/Introduction/


## Contact

Soumya Banerjee

sb2333@cam.ac.uk

