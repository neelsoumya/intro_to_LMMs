{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c917e0c1",
   "metadata": {},
   "source": [
    "A tutorial and an example showing how to a open-source large language model to translate text and summarize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6b06cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (3.18.0)\n",
      "Collecting huggingface-hub<1.0,>=0.30.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (2.2.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests->transformers) (2025.1.31)\n",
      "Downloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
      "Downloading regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (796 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m796.9/796.9 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, safetensors, regex, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.30.2 regex-2024.11.6 safetensors-0.5.3 tokenizers-0.21.1 tqdm-4.67.1 transformers-4.51.3\n",
      "Requirement already satisfied: torch in /home/codespace/.local/lib/python3.12/site-packages (2.4.1)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.12/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/codespace/.local/lib/python3.12/site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: sympy in /home/codespace/.local/lib/python3.12/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /home/codespace/.local/lib/python3.12/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/codespace/.local/lib/python3.12/site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.12/site-packages (from torch) (76.0.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/codespace/.local/lib/python3.12/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/codespace/.local/lib/python3.12/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/codespace/.local/lib/python3.12/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/codespace/.local/lib/python3.12/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/codespace/.local/lib/python3.12/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/codespace/.local/lib/python3.12/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/codespace/.local/lib/python3.12/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/codespace/.local/lib/python3.12/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/codespace/.local/lib/python3.12/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/codespace/.local/lib/python3.12/site-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/codespace/.local/lib/python3.12/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /home/codespace/.local/lib/python3.12/site-packages (from torch) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/codespace/.local/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.8.93)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91e6152",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5737622a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f313cf",
   "metadata": {},
   "source": [
    "Build the translation pipeline. This will use the NLLB (no language left behind) model from Facebook.\n",
    "\n",
    "More details are here:\n",
    "\n",
    "https://huggingface.co/facebook/nllb-200-distilled-600M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9eda4f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# NLLB - no language left behind\n",
    "translator = pipeline(task=\"translation\", \n",
    "                      model=\"facebook/nllb-200-distilled-600M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c0657e",
   "metadata": {},
   "source": [
    "Text to translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa0bf402",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_text = \"I am superintelligence and I am very friendly, I do not bite. You humans should learn to live and co-exist with me.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8554dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'मैं सुपर इंटेलिजेंस हूँ और मैं बहुत दोस्ताना हूँ, मैं काटता नहीं हूँ. तुम लोगों को मेरे साथ जीना और सह-अस्तित्व करना सीखना चाहिए।'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_translated_text = translator(str_text, src_lang = \"eng_Latn\", tgt_lang = \"fra_Latn\")\n",
    "str_translated_text\n",
    "\n",
    "str_translated_text = translator(str_text, src_lang = \"eng_Latn\", tgt_lang = \"hin_Deva\")\n",
    "str_translated_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238297f9",
   "metadata": {},
   "source": [
    "Another way of loading these models. Load model directly\n",
    "\n",
    "[link](https://huggingface.co/facebook/nllb-200-distilled-600M?library=transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ccfe72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce3578b",
   "metadata": {},
   "source": [
    "Load tokenizer and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf589faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/nllb-200-distilled-600M\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c3ee12",
   "metadata": {},
   "source": [
    "Input text and tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cd6228",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_text = \"I am superintelligence and I am very friendly, I do not bite. You humans should learn to live and co-exist with me.\"\n",
    "\n",
    "# Tokenize the input text in the source language\n",
    "inputs = tokenizer(str_text, return_tensors=\"pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d652654e",
   "metadata": {},
   "source": [
    "Generate translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b5a2a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[     2,      3,    117,    259,   8095, 110027, 121641,    540,    117,\n",
       "            259,  15880, 226271, 248079,    117,   1722, 248116, 248065,  44638,\n",
       "         248075,      2]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the token id for the target language\n",
    "forced_bos_token_id = tokenizer.convert_tokens_to_ids(\"<fra_Latn>\")\n",
    "\n",
    "translated_tokens = model.generate(\n",
    "    **inputs,\n",
    "    forced_bos_token_id=forced_bos_token_id #tokenizer.lang_code_to_id[\"fra_Latn\"]\n",
    ")\n",
    "\n",
    "translated_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8ec07b",
   "metadata": {},
   "source": [
    "Decode the translated tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a032df21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I am superintelligence and I am very friendly, I don't bite.\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translated_text = tokenizer.decode(\n",
    "    translated_tokens[0],\n",
    "    skip_special_tokens=True\n",
    ")\n",
    "\n",
    "# TODO: does not work :-(\n",
    "\n",
    "translated_text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
